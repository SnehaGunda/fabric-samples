{"cells":[{"cell_type":"markdown","source":["# JobInsight Sample Notebook\n","This notebook demonstrates how to use the JobInsight diagnostic library to analyze completed Spark jobs in Microsoft Fabric.\n","It includes:\n","- Analyzing a completed Spark job\n","- Persisting metrics to Lakehouse tables\n","- Reloading previously analyzed results\n","- Copying event logs to ABFSS\n","\n","**Note:** This notebook uses Scala."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"667699fd-23df-45a3-a823-ad3811a66a42"},{"cell_type":"code","source":["// Step 0: Configure Spark session for large event logs\n","import org.apache.spark.sql.SparkSession\n","\n","val spark = SparkSession.builder()\n","  .appName(\"JobInsightApp\")\n","  .config(\"spark.eventLog.jsonOption.maxStringLength\", \"2000000000\")\n","  .config(\"spark.eventLog.jsonOption.maxDepth\", \"2000000000\")\n","  .getOrCreate()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"scala","language_group":"synapse_pyspark"}},"id":"f0e4c32b-763f-4d5e-96a6-7550ca90d852"},{"cell_type":"code","source":["// Step 1: Analyze a completed Spark job\n","import com.microsoft.jobinsight.diagnostic.SparkDiagnostic\n","\n","// Replace the placeholders with actual values from your Spark application\n","val workspaceId    = \"<your-workspace-id>\"\n","val artifactId     = \"<your-artifact-id>\"\n","val livyId         = \"<your-livy-id>\"\n","val jobType        = \"sessions\"  // \"sessions\" for notebooks, \"batches\" for job definitions\n","val attemptId      = 1           // Optional: default is 1\n","\n","val stateStorePath = \"abfss://<container>@<storage_account>.dfs.core.windows.net/<path>/state_store\"\n","\n","if (mssparkutils.fs.exists(stateStorePath)) {\n","    mssparkutils.fs.rm(stateStorePath, true)\n","}\n","\n","val jobInsight = SparkDiagnostic.analyze(\n","    workspaceId,\n","    artifactId,\n","    livyId,\n","    jobType,\n","    stateStorePath\n",")\n","\n","val queries    = jobInsight.queries\n","val jobs       = jobInsight.jobs\n","val stages     = jobInsight.stages\n","val tasks      = jobInsight.tasks\n","val executors  = jobInsight.executors\n","\n","queries.show()\n","jobs.show()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"scala","language_group":"synapse_pyspark"}},"id":"60146ca5-2a08-492d-a1df-eba1e7d24324"},{"cell_type":"code","source":["// Step 2: Save metrics to a Lakehouse table\n","queries.write\n","  .format(\"delta\")\n","  .mode(\"overwrite\")\n","  .saveAsTable(\"Queries\")\n","\n","// Repeat for jobs, stages, etc., if needed\n","// jobs.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"Jobs\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"scala","language_group":"synapse_pyspark"}},"id":"1f2b0c3d-c542-4f0b-bbea-71a3c63a59db"},{"cell_type":"code","source":["// Step 3: Reload a previously analyzed job\n","val jobInsightReloaded = SparkDiagnostic.loadJobInsight(stateStorePath)\n","\n","val queriesReloaded    = jobInsightReloaded.queries\n","val jobsReloaded       = jobInsightReloaded.jobs\n","val stagesReloaded     = jobInsightReloaded.stages\n","val tasksReloaded      = jobInsightReloaded.tasks\n","val executorsReloaded  = jobInsightReloaded.executors\n","\n","queriesReloaded.show()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"scala","language_group":"synapse_pyspark"}},"id":"498a78a4-1489-49fc-9d81-6f4760ed8a4c"},{"cell_type":"code","source":["// Step 4: Copy Spark event logs to ABFSS\n","import com.microsoft.jobinsight.diagnostic.LogUtils\n","\n","val targetDirectory = \"abfss://<container>@<storage_account>.dfs.core.windows.net/<path>/logs\"\n","val asyncMode       = true\n","\n","val contentLength = LogUtils.copyEventLog(\n","  workspaceId,\n","  artifactId,\n","  livyId,\n","  jobType,\n","  targetDirectory,\n","  asyncMode,\n","  attemptId\n",")\n","\n","println(s\"Copied event log content size: $contentLength bytes\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"scala","language_group":"synapse_pyspark"}},"id":"154398c3-6b79-48a4-8ab6-92bad48ceaeb"}],"metadata":{"language_info":{"name":"scala"},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"synapse_pyspark","language":null,"name":"synapse_pyspark"},"a365ComputeOptions":null,"sessionKeepAliveTimeout":0,"microsoft":{"language":"scala","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"5bdde6e4-d732-46da-96fc-f0c1b008ca5e","default_lakehouse_name":"JobInsight","default_lakehouse_workspace_id":"f111a4cf-f225-4529-b05d-c371b66dbdde","known_lakehouses":[{"id":"5bdde6e4-d732-46da-96fc-f0c1b008ca5e"}]}}},"nbformat":4,"nbformat_minor":5}